{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "eCJPlUdVcpzz",
        "outputId": "91c7b938-cb53-4a81-988e-3ddb68eaaa07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n#Test the convolutions with 1 image, to put in the article\\n# Test\\ndf_train = pd.read_csv('train.csv')\\nimg = df_train.iloc[40,:].values[1:]\\nimg = np.reshape(img,(28,28))\\nplt.imshow(img, cmap='gray')\\nplt.show()\\nprint(img.shape)\\nplt.savefig('images/original_image.png', format='png', dpi=1200)\\n\\n# Test with a convolution of 16 filters of size 3x3\\nmy_conv = ConvolutionLayer(32,3)\\noutput = my_conv.forward_prop(img)\\n# See the dimensions of the output volume, they follow the usual formula\\nprint(output.shape)\\n\\n# Plot 16th volume after the convolution\\nplt.imshow(output[:,:,15], cmap='gray')\\nplt.show()\\nplt.savefig('images/image_convolved.png', format='png', dpi=1200)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import jit, prange\n",
        "from numba import config\n",
        "from numba import jit, cuda\n",
        "#config.THREADING_LAYER = 'omp'\n",
        "\n",
        "class ConvolutionLayer:\n",
        "    def __init__(self, kernel_num, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
        "        \"\"\"\n",
        "        self.kernel_num = kernel_num\n",
        "        self.kernel_size = kernel_size\n",
        "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization\n",
        "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during convolution.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        self.image = image\n",
        "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
        "        patches = np.empty((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_size, self.kernel_size))\n",
        "        for h in range(image_h-self.kernel_size+1):\n",
        "            for w in range(image_w-self.kernel_size+1):\n",
        "                patches[h, w] = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
        "        return patches\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        \"\"\"\n",
        "        Perform forward propagation for the convolutional layer.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        # Initialize the convolution output volume of the correct size\n",
        "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
        "        # Unpack the generator\n",
        "        patches = self.patches_generator(image)\n",
        "        block_size = (16, 16)\n",
        "        grid_size = (math.ceil(convolution_output.shape[1] / block_size[0]),\n",
        "                     math.ceil(convolution_output.shape[0] / block_size[1]))\n",
        "        cnn_forward_kernel[grid_size, block_size](patches, self.kernels, convolution_output)\n",
        "        cuda.synchronize()\n",
        "        return convolution_output\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically max pooling layer.\n",
        "        It updates the kernels' weights\n",
        "        \"\"\"\n",
        "        # Initialize gradient of the loss function with respect to the kernel weights\n",
        "        dE_dk = np.zeros(self.kernels.shape)\n",
        "        patches = self.patches_generator(self.image)\n",
        "        block_size = (16, 4, 4)\n",
        "        grid_size = (math.ceil(dE_dk.shape[2] / block_size[0]),\n",
        "                     math.ceil(dE_dk.shape[1] / block_size[1]),\n",
        "                     math.ceil(dE_dk.shape[0] / block_size[2]))\n",
        "        cnn_backward_kernel[grid_size, block_size](patches, dE_dY, dE_dk)\n",
        "        cuda.synchronize()\n",
        "        # Update the parameters\n",
        "        self.kernels -= alpha*dE_dk\n",
        "        return dE_dk\n",
        "\n",
        "\n",
        "class MaxPoolingLayer:\n",
        "    def __init__(self, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the size of the kernel\n",
        "        \"\"\"\n",
        "        self.kernel_size = kernel_size\n",
        "    @cuda.jit\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1] // self.kernel_size\n",
        "        self.image = image\n",
        "        c,r=cuda.grid(2)\n",
        "        if r < output_h and c < output_w:\n",
        "              patch = image[(r*self.kernel_size):(r*self.kernel_size+self.kernel_size), (c*self.kernel_size):(c*self.kernel_size+self.kernel_size)]\n",
        "              yield patch, r, c\n",
        "\n",
        "    @cuda.jit\n",
        "    def forward_prop(self, image):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
        "        c,r=cuda.grid(2)\n",
        "        block_size = (32, 32)\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1]\n",
        "        grid_size = (math.ceil(image.shape[1] / block_size[0]),\n",
        "             math.ceil(image.shape[0] / block_size[1]))\n",
        "        if r < output_h and c < output_w:\n",
        "            for patch, r, c in self.patches_generator[grid_size, block_size](image):\n",
        "                max_pooling_output[r,c] = np.amax(patch, axis=(0,1))\n",
        "            return max_pooling_output\n",
        "\n",
        "\n",
        "    def back_prop(self, dE_dY):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk = np.zeros(self.image.shape)\n",
        "        for patch,h,w in self.patches_generator(self.image):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "\n",
        "            for idx_h in range(image_h):\n",
        "                for idx_w in range(image_w):\n",
        "                    for idx_k in range(num_kernels):\n",
        "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
        "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
        "            return dE_dk\n",
        "\n",
        "class SoftmaxLayer:\n",
        "    \"\"\"\n",
        "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_units, output_units):\n",
        "        # Initiallize weights and biases\n",
        "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
        "        self.bias = np.zeros(output_units)\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "      self.original_shape = image.shape # stored for backprop\n",
        "      # Flatten the image\n",
        "      #print(\"image: \", image)\n",
        "      image_flattened = image.flatten()\n",
        "      #print(\"image_flattened: \", image_flattened)\n",
        "      self.flattened_input = image_flattened # stored for backprop\n",
        "\n",
        "      # Perform matrix multiplication and add bias\n",
        "      C = np.empty(10)\n",
        "      dA = cuda.to_device(image_flattened)\n",
        "      dB = cuda.to_device(self.weight)\n",
        "      dC = cuda.to_device(C)\n",
        "      dot[(self.weight.shape[0]+255)//256, 256](dA,dB,dC)\n",
        "      #cu_matrix_vector[(dZ_dX.shape[0]+511)//512, 512](dZ_dX,dE_dZ,C)\n",
        "      result = dC.copy_to_host()\n",
        "      first_output = result  + self.bias\n",
        "      self.output = first_output\n",
        "      # Apply softmax activation\n",
        "      softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
        "\n",
        "      return softmax_output\n",
        "\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "      for i, gradient in enumerate(dE_dY):\n",
        "        if gradient == 0:\n",
        "          continue\n",
        "        transformation_eq = np.exp(self.output)\n",
        "        S_total = np.sum(transformation_eq)\n",
        "\n",
        "        # Compute gradients with respect to output (Z)\n",
        "        dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
        "        dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "\n",
        "        # Compute gradients of output Z with respect to weight, bias, input\n",
        "        dZ_dw = self.flattened_input\n",
        "        dZ_db = 1\n",
        "        dZ_dX = self.weight\n",
        "\n",
        "        # Gradient of loss with respect ot output\n",
        "        dE_dZ = gradient * dY_dZ\n",
        "\n",
        "        # Gradient of loss with respect to weight, bias, input\n",
        "        dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
        "        dE_db = dE_dZ * dZ_db\n",
        "\n",
        "        # Matrix-vector multiply function\n",
        "        C = np.empty(dZ_dX.shape[0])\n",
        "        dA = cuda.to_device(dZ_dX)\n",
        "        dB = cuda.to_device(dE_dZ)\n",
        "        dC = cuda.to_device(C)\n",
        "        cu_matrix_vector[(dZ_dX.shape[0]+127)//128, 128](dA,dB,dC)\n",
        "        dE_dX = dC.copy_to_host()\n",
        "\n",
        "        # Update parameters\n",
        "        self.weight -= alpha* (dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis])\n",
        "        self.bias -= alpha * (dE_dZ * dZ_db)\n",
        "\n",
        "        return dE_dX.reshape(self.original_shape)\n",
        "\n",
        "\n",
        "def CNN_forward(image, label, layers):\n",
        "    output = image/255.\n",
        "    for layer in layers:\n",
        "      if type(layer) == MaxPoolingLayer:\n",
        "        output = forward_prop(output,kernel_size=2)\n",
        "      elif type(layer) == ConvolutionLayer:\n",
        "        output = layer.forward_prop(output)\n",
        "        image_backprob_max=output\n",
        "      else:\n",
        "        output = layer.forward_prop(output)\n",
        "    # Compute loss (cross-entropy) and accuracy\n",
        "    loss = -np.log(output[label])\n",
        "    accuracy = 1 if np.argmax(output) == label else 0\n",
        "    return output, loss, accuracy,image_backprob_max\n",
        "\n",
        "\n",
        "def CNN_backprop(gradient, layers,image_backprob_max, alpha=0.05):\n",
        "    grad_back = gradient\n",
        "    for layer in layers[::-1]:\n",
        "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
        "            grad_back = layer.back_prop(grad_back, alpha)\n",
        "        elif type(layer) == MaxPoolingLayer:\n",
        "            grad_back = back_prop(image_backprob_max,grad_back,kernel_size=2)\n",
        "    return grad_back\n",
        "\n",
        "\n",
        "def CNN_training(image, label, layers, alpha=0.05):\n",
        "    # Forward step\n",
        "    output, loss, accuracy,image_backprob_max = CNN_forward(image, label, layers)\n",
        "\n",
        "    # Initial gradient\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1/output[label]\n",
        "\n",
        "    # Backprop step\n",
        "    gradient_back = CNN_backprop(gradient, layers,image_backprob_max, alpha)\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#Test the convolutions with 1 image, to put in the article\n",
        "# Test\n",
        "df_train = pd.read_csv('train.csv')\n",
        "img = df_train.iloc[40,:].values[1:]\n",
        "img = np.reshape(img,(28,28))\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "plt.savefig('images/original_image.png', format='png', dpi=1200)\n",
        "\n",
        "# Test with a convolution of 16 filters of size 3x3\n",
        "my_conv = ConvolutionLayer(32,3)\n",
        "output = my_conv.forward_prop(img)\n",
        "# See the dimensions of the output volume, they follow the usual formula\n",
        "print(output.shape)\n",
        "\n",
        "# Plot 16th volume after the convolution\n",
        "plt.imshow(output[:,:,15], cmap='gray')\n",
        "plt.show()\n",
        "plt.savefig('images/image_convolved.png', format='png', dpi=1200)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def cnn_forward_kernel(patches, kernels, convolution_output):\n",
        "    r, c = cuda.grid(2)\n",
        "\n",
        "    if r < patches.shape[0] and c < patches.shape[1]:\n",
        "        for k in range(kernels.shape[0]):\n",
        "            sum = 0\n",
        "            for i in range(kernels.shape[1]):\n",
        "                for j in range(kernels.shape[2]):\n",
        "                    sum += patches[r, c, i, j] * kernels[k, i, j]\n",
        "            convolution_output[r, c, k] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def cnn_backward_kernel(patches, dE_dY, dE_dk):\n",
        "    x, y, z = cuda.grid(3)\n",
        "\n",
        "    if x < dE_dk.shape[0] and y < dE_dk.shape[1] and z < dE_dk.shape[2]:\n",
        "        temp = 0\n",
        "        for h in range(patches.shape[0]):\n",
        "            for w in range(patches.shape[1]):\n",
        "                temp += patches[h, w, y, z] * dE_dY[h, w, x]\n",
        "        dE_dk[x, y, z] = temp"
      ],
      "metadata": {
        "id": "rooLF511owYL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGe9Ifz26Oay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@cuda.jit(device=True)\n",
        "def patches_generator(image,kernel_size):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // kernel_size\n",
        "        output_w = image.shape[1] // kernel_size\n",
        "        #self.image = image\n",
        "        #c,r=cuda.grid(2)\n",
        "        for h in range(output_h):\n",
        "            for w in range(output_w):\n",
        "                patch = image[(h*kernel_size):(h*kernel_size+kernel_size), (w*kernel_size):(w*kernel_size+kernel_size)]\n",
        "                yield patch,h,w\n",
        "\n",
        "def forward_prop(image,kernel_size):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//kernel_size, image_w//kernel_size, num_kernels))\n",
        "        for patch, h, w in patches_generator(image,kernel_size):\n",
        "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
        "        return max_pooling_output\n",
        "\n",
        "\n",
        "\n",
        "def back_prop(image,dE_dY,kernel_size):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk_temp1 = np.zeros(image.shape)\n",
        "        #dE_dk=np.ascontiguousarray(dE_dk_temp1)\n",
        "        #cuda.pinned(dE_dk)\n",
        "        for patch,h,w in patches_generator(image,kernel_size):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "            block_size = (16, 16)\n",
        "            grid_size = (math.ceil(image_w / block_size[0]),\n",
        "                        math.ceil(image_h / block_size[1]))\n",
        "            patch=np.ascontiguousarray(patch)\n",
        "\n",
        "            dA=cuda.to_device(patch)\n",
        "            #print(\"hihi2\")\n",
        "           # dB=cuda.to_device(max_val)\n",
        "            #dC=cuda.to_device(dE_dY)\n",
        "            dE=cuda.to_device(dE_dk_temp1)\n",
        "            #print(\"hihi\")\n",
        "            back_prob_sup[grid_size, block_size](image_h,image_w,num_kernels,dA,max_val,dE_dY,dE,h,w,kernel_size)\n",
        "            dE_dk=dE.copy_to_host()\n",
        "            #print(dE_dk)\n",
        "            #stream.synchronize()\n",
        "            return dE_dk\n",
        "\n",
        "@cuda.jit\n",
        "def back_prob_sup(image_h,image_w,num_kernels,patch,max_val,dE_dY,dE_dk,h,w,kernel_size):\n",
        "    c,r=cuda.grid(2)\n",
        "    #print(\"hihi\")\n",
        "    if r < image_h and c < image_w:\n",
        "          for idx_k in range(num_kernels):\n",
        "                if patch[r,c,idx_k] == max_val[idx_k]:\n",
        "                  #print(\"hihi\")\n",
        "                  dE_dk[h*kernel_size+r, w*kernel_size+c, idx_k] = dE_dY[h,w,idx_k]\n",
        "    #return dE_dk"
      ],
      "metadata": {
        "id": "2mLxP8vGcrJk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def dot(a, b, c):\n",
        "  col = cuda.grid(1)\n",
        "  if (col < b.shape[1]):\n",
        "    sum = 0.0\n",
        "    for i in range(b.shape[0]):\n",
        "      sum += a[i] * b[i, col]\n",
        "    c[col] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def cu_matrix_vector(A, b, c):\n",
        "  row = cuda.grid(1)\n",
        "  if (row < A.shape[0]):\n",
        "    sum = 0.0\n",
        "    for i in range(A.shape[1]):\n",
        "      sum += A[row, i] * b[i]\n",
        "    c[row] = sum"
      ],
      "metadata": {
        "id": "LOVIFj25zufr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numba import cuda\n",
        "#from utils import *\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "def main():\n",
        "  # Load training data\n",
        "  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  X_train = X_train[:10000]\n",
        "  y_train = y_train[:10000]\n",
        "\n",
        "  # Define the network\n",
        "  layers = [\n",
        "    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
        "    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)\n",
        "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
        "    ]\n",
        "\n",
        "  for epoch in range(1):\n",
        "    print('Epoch {} ->'.format(epoch+1))\n",
        "    # Shuffle training data\n",
        "    permutation = np.random.permutation(len(X_train))\n",
        "    X_train = X_train[permutation]\n",
        "    y_train = y_train[permutation]\n",
        "    # Training the CNN\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
        "      if i % 100 == 0: # Every 100 examples\n",
        "        print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "      image_backprob_max=image\n",
        "      loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
        "      loss += loss_1\n",
        "      accuracy += accuracy_1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  start = time.time()\n",
        "  main()\n",
        "  end = time.time()\n",
        "  print(f'Processing time: {end - start} s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBDS6JnLcy2t",
        "outputId": "bd990ff0-3076-4de2-9791-8e888157fce9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ->\n",
            "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 11 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 22 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 101. For the last 100 steps: average loss 1.9125924102695244, accuracy 38\n",
            "Step 201. For the last 100 steps: average loss 1.1524619328957568, accuracy 61\n",
            "Step 301. For the last 100 steps: average loss 0.8427925436771072, accuracy 75\n",
            "Step 401. For the last 100 steps: average loss 0.6812027035574276, accuracy 81\n",
            "Step 501. For the last 100 steps: average loss 0.609201943954803, accuracy 85\n",
            "Step 601. For the last 100 steps: average loss 0.5241411681466849, accuracy 85\n",
            "Step 701. For the last 100 steps: average loss 0.6334343813585073, accuracy 82\n",
            "Step 801. For the last 100 steps: average loss 0.5803650026036764, accuracy 82\n",
            "Step 901. For the last 100 steps: average loss 0.5479547773331299, accuracy 82\n",
            "Step 1001. For the last 100 steps: average loss 0.3912323309632928, accuracy 91\n",
            "Step 1101. For the last 100 steps: average loss 0.5351177270499027, accuracy 89\n",
            "Step 1201. For the last 100 steps: average loss 0.32963504388009196, accuracy 87\n",
            "Step 1301. For the last 100 steps: average loss 0.46225959317578286, accuracy 86\n",
            "Step 1401. For the last 100 steps: average loss 0.44663676707852396, accuracy 84\n",
            "Step 1501. For the last 100 steps: average loss 0.6602735126875352, accuracy 77\n",
            "Step 1601. For the last 100 steps: average loss 0.4738824482201749, accuracy 83\n",
            "Step 1701. For the last 100 steps: average loss 0.46548127391006877, accuracy 89\n",
            "Step 1801. For the last 100 steps: average loss 0.374217615655, accuracy 89\n",
            "Step 1901. For the last 100 steps: average loss 0.4326927486693577, accuracy 85\n",
            "Step 2001. For the last 100 steps: average loss 0.4511579712401814, accuracy 90\n",
            "Step 2101. For the last 100 steps: average loss 0.40339901431525277, accuracy 88\n",
            "Step 2201. For the last 100 steps: average loss 0.4137366009587155, accuracy 85\n",
            "Step 2301. For the last 100 steps: average loss 0.375138814986457, accuracy 90\n",
            "Step 2401. For the last 100 steps: average loss 0.46184342216792607, accuracy 88\n",
            "Step 2501. For the last 100 steps: average loss 0.5167172821342466, accuracy 85\n",
            "Step 2601. For the last 100 steps: average loss 0.24868200665708937, accuracy 97\n",
            "Step 2701. For the last 100 steps: average loss 0.36508313889120325, accuracy 91\n",
            "Step 2801. For the last 100 steps: average loss 0.3847609329744975, accuracy 84\n",
            "Step 2901. For the last 100 steps: average loss 0.324051865259203, accuracy 87\n",
            "Step 3001. For the last 100 steps: average loss 0.30374291965733874, accuracy 89\n",
            "Step 3101. For the last 100 steps: average loss 0.4834454157796613, accuracy 82\n",
            "Step 3201. For the last 100 steps: average loss 0.3307858004849576, accuracy 87\n",
            "Step 3301. For the last 100 steps: average loss 0.46337462869494184, accuracy 87\n",
            "Step 3401. For the last 100 steps: average loss 0.32361565186849534, accuracy 92\n",
            "Step 3501. For the last 100 steps: average loss 0.44913459552559354, accuracy 87\n",
            "Step 3601. For the last 100 steps: average loss 0.3696401656836198, accuracy 89\n",
            "Step 3701. For the last 100 steps: average loss 0.49421405656645434, accuracy 88\n",
            "Step 3801. For the last 100 steps: average loss 0.3940645623079248, accuracy 87\n",
            "Step 3901. For the last 100 steps: average loss 0.41618726396442235, accuracy 85\n",
            "Step 4001. For the last 100 steps: average loss 0.39995085584994944, accuracy 88\n",
            "Step 4101. For the last 100 steps: average loss 0.4736868165459985, accuracy 86\n",
            "Step 4201. For the last 100 steps: average loss 0.5123991046175772, accuracy 87\n",
            "Step 4301. For the last 100 steps: average loss 0.31595014499086943, accuracy 91\n",
            "Step 4401. For the last 100 steps: average loss 0.5061891255574734, accuracy 84\n",
            "Step 4501. For the last 100 steps: average loss 0.33548367844678517, accuracy 89\n",
            "Step 4601. For the last 100 steps: average loss 0.4003361126400486, accuracy 88\n",
            "Step 4701. For the last 100 steps: average loss 0.2896310617997118, accuracy 89\n",
            "Step 4801. For the last 100 steps: average loss 0.4753282976457454, accuracy 88\n",
            "Step 4901. For the last 100 steps: average loss 0.25674688539876855, accuracy 93\n",
            "Step 5001. For the last 100 steps: average loss 0.434247867819052, accuracy 87\n",
            "Step 5101. For the last 100 steps: average loss 0.242865026521147, accuracy 93\n",
            "Step 5201. For the last 100 steps: average loss 0.41964152620123424, accuracy 88\n",
            "Step 5301. For the last 100 steps: average loss 0.2736985031856683, accuracy 94\n",
            "Step 5401. For the last 100 steps: average loss 0.2967878321696534, accuracy 91\n",
            "Step 5501. For the last 100 steps: average loss 0.4531631966294132, accuracy 85\n",
            "Step 5601. For the last 100 steps: average loss 0.21257624745344988, accuracy 93\n",
            "Step 5701. For the last 100 steps: average loss 0.26221469396278874, accuracy 92\n",
            "Step 5801. For the last 100 steps: average loss 0.28782062621766596, accuracy 92\n",
            "Step 5901. For the last 100 steps: average loss 0.30552988233123446, accuracy 90\n",
            "Step 6001. For the last 100 steps: average loss 0.3060617453383948, accuracy 90\n",
            "Step 6101. For the last 100 steps: average loss 0.4799684242711622, accuracy 87\n",
            "Step 6201. For the last 100 steps: average loss 0.32583250382961154, accuracy 91\n",
            "Step 6301. For the last 100 steps: average loss 0.4374509989891896, accuracy 85\n",
            "Step 6401. For the last 100 steps: average loss 0.37683056002645215, accuracy 87\n",
            "Step 6501. For the last 100 steps: average loss 0.5384191229061627, accuracy 89\n",
            "Step 6601. For the last 100 steps: average loss 0.417379268987651, accuracy 87\n",
            "Step 6701. For the last 100 steps: average loss 0.4970186231680458, accuracy 86\n",
            "Step 6801. For the last 100 steps: average loss 0.47528577528053356, accuracy 87\n",
            "Step 6901. For the last 100 steps: average loss 0.3104500569473304, accuracy 92\n",
            "Step 7001. For the last 100 steps: average loss 0.35935083749602403, accuracy 89\n",
            "Step 7101. For the last 100 steps: average loss 0.2423988533945141, accuracy 92\n",
            "Step 7201. For the last 100 steps: average loss 0.2599287873558934, accuracy 93\n",
            "Step 7301. For the last 100 steps: average loss 0.6011330660371818, accuracy 88\n",
            "Step 7401. For the last 100 steps: average loss 0.30412597720562035, accuracy 91\n",
            "Step 7501. For the last 100 steps: average loss 0.40441932206077935, accuracy 87\n",
            "Step 7601. For the last 100 steps: average loss 0.22463812895371704, accuracy 93\n",
            "Step 7701. For the last 100 steps: average loss 0.38201718247647654, accuracy 86\n",
            "Step 7801. For the last 100 steps: average loss 0.3529065474877452, accuracy 86\n",
            "Step 7901. For the last 100 steps: average loss 0.18612038545191706, accuracy 95\n",
            "Step 8001. For the last 100 steps: average loss 0.29595745769912934, accuracy 92\n",
            "Step 8101. For the last 100 steps: average loss 0.28698698023724, accuracy 90\n",
            "Step 8201. For the last 100 steps: average loss 0.3613117043419971, accuracy 90\n",
            "Step 8301. For the last 100 steps: average loss 0.4164832293442879, accuracy 87\n",
            "Step 8401. For the last 100 steps: average loss 0.20152534932653082, accuracy 96\n",
            "Step 8501. For the last 100 steps: average loss 0.36441406352130845, accuracy 89\n",
            "Step 8601. For the last 100 steps: average loss 0.370032820495064, accuracy 88\n",
            "Step 8701. For the last 100 steps: average loss 0.25335679756096324, accuracy 91\n",
            "Step 8801. For the last 100 steps: average loss 0.26290985467926814, accuracy 95\n",
            "Step 8901. For the last 100 steps: average loss 0.20709259147878759, accuracy 95\n",
            "Step 9001. For the last 100 steps: average loss 0.4333107035780904, accuracy 88\n",
            "Step 9101. For the last 100 steps: average loss 0.2882766421939557, accuracy 91\n",
            "Step 9201. For the last 100 steps: average loss 0.22148636303837027, accuracy 94\n",
            "Step 9301. For the last 100 steps: average loss 0.4803330699243751, accuracy 86\n",
            "Step 9401. For the last 100 steps: average loss 0.31123528933341493, accuracy 90\n",
            "Step 9501. For the last 100 steps: average loss 0.6401375288386252, accuracy 83\n",
            "Step 9601. For the last 100 steps: average loss 0.32107787856907377, accuracy 92\n",
            "Step 9701. For the last 100 steps: average loss 0.30802766102677853, accuracy 90\n",
            "Step 9801. For the last 100 steps: average loss 0.32052303719713104, accuracy 91\n",
            "Step 9901. For the last 100 steps: average loss 0.3408817362627874, accuracy 90\n",
            "Processing time: 114.41391944885254 s\n"
          ]
        }
      ]
    }
  ]
}