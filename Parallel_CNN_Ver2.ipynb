{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCJPlUdVcpzz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import config\n",
        "from numba import jit, cuda, prange\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import time\n",
        "#config.THREADING_LAYER = 'omp'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5v1zUu5wY1Yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Parallell Convoluner Layer v1:"
      ],
      "metadata": {
        "id": "oYTM62eTY1af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def cnn_forward_kernel(patches, kernels, convolution_output):\n",
        "    r, c = cuda.grid(2)\n",
        "\n",
        "    if r < patches.shape[0] and c < patches.shape[1]:\n",
        "        for k in range(kernels.shape[0]):\n",
        "            sum = 0\n",
        "            for i in range(kernels.shape[1]):\n",
        "                for j in range(kernels.shape[2]):\n",
        "                    sum += patches[r, c, i, j] * kernels[k, i, j]\n",
        "            convolution_output[r, c, k] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def cnn_backward_kernel(patches, dE_dY, dE_dk):\n",
        "    x, y, z = cuda.grid(3)\n",
        "\n",
        "    if x < dE_dk.shape[0] and y < dE_dk.shape[1] and z < dE_dk.shape[2]:\n",
        "        temp = 0\n",
        "        for h in range(patches.shape[0]):\n",
        "            for w in range(patches.shape[1]):\n",
        "                temp += patches[h, w, y, z] * dE_dY[h, w, x]\n",
        "        dE_dk[x, y, z] = temp"
      ],
      "metadata": {
        "id": "rooLF511owYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Sz09moCZTXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Parallell Max Pooling Layer v1:"
      ],
      "metadata": {
        "id": "K05mzy-EZTZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@cuda.jit(device=True)\n",
        "def patches_generator(image,kernel_size):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // kernel_size\n",
        "        output_w = image.shape[1] // kernel_size\n",
        "        #self.image = image\n",
        "        #c,r=cuda.grid(2)\n",
        "        for h in range(output_h):\n",
        "            for w in range(output_w):\n",
        "                patch = image[(h*kernel_size):(h*kernel_size+kernel_size), (w*kernel_size):(w*kernel_size+kernel_size)]\n",
        "                yield patch,h,w\n",
        "\n",
        "def forward_prop(image,kernel_size):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//kernel_size, image_w//kernel_size, num_kernels))\n",
        "        for patch, h, w in patches_generator(image,kernel_size):\n",
        "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
        "        return max_pooling_output\n",
        "\n",
        "\n",
        "\n",
        "def back_prop(image,dE_dY,kernel_size):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk_temp1 = np.zeros(image.shape)\n",
        "        #dE_dk=np.ascontiguousarray(dE_dk_temp1)\n",
        "        #cuda.pinned(dE_dk)\n",
        "        for patch,h,w in patches_generator(image,kernel_size):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "            block_size = (16, 16)\n",
        "            grid_size = (math.ceil(image_w / block_size[0]),\n",
        "                        math.ceil(image_h / block_size[1]))\n",
        "            patch=np.ascontiguousarray(patch)\n",
        "\n",
        "            dA=cuda.to_device(patch)\n",
        "            dE=cuda.to_device(dE_dk_temp1)\n",
        "            back_prob_sup[grid_size, block_size](image_h,image_w,num_kernels,dA,max_val,dE_dY,dE,h,w,kernel_size)\n",
        "            dE_dk=dE.copy_to_host()\n",
        "            return dE_dk\n",
        "\n",
        "@cuda.jit\n",
        "def back_prob_sup(image_h,image_w,num_kernels,patch,max_val,dE_dY,dE_dk,h,w,kernel_size):\n",
        "    c,r=cuda.grid(2)\n",
        "    #print(\"hihi\")\n",
        "    if r < image_h and c < image_w:\n",
        "          for idx_k in range(num_kernels):\n",
        "                if patch[r,c,idx_k] == max_val[idx_k]:\n",
        "                  #print(\"hihi\")\n",
        "                  dE_dk[h*kernel_size+r, w*kernel_size+c, idx_k] = dE_dY[h,w,idx_k]\n",
        "    #return dE_dk"
      ],
      "metadata": {
        "id": "2mLxP8vGcrJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Parallell Soft max Layer v1:"
      ],
      "metadata": {
        "id": "AMRZrx-iwVvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def dot(a, b, c):\n",
        "  col = cuda.grid(1)\n",
        "  if (col < b.shape[1]):\n",
        "    sum = 0.0\n",
        "    for i in range(b.shape[0]):\n",
        "      sum += a[i] * b[i, col]\n",
        "    c[col] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def cu_matrix_vector(A, b, c):\n",
        "  row = cuda.grid(1)\n",
        "  if (row < A.shape[0]):\n",
        "    sum = 0.0\n",
        "    for i in range(A.shape[1]):\n",
        "      sum += A[row, i] * b[i]\n",
        "    c[row] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def matmul(A,B,C):\n",
        "  i,j = cuda.grid(2)\n",
        "  if i < C.shape[0] and j < C.shape[1]:\n",
        "    tmp = A[i,0] * B[0,j]\n",
        "    C[i,j] = tmp"
      ],
      "metadata": {
        "id": "LOVIFj25zufr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN classes"
      ],
      "metadata": {
        "id": "1_TlPrapxASM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionLayer:\n",
        "    def __init__(self, kernel_num, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
        "        \"\"\"\n",
        "        self.kernel_num = kernel_num\n",
        "        self.kernel_size = kernel_size\n",
        "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization\n",
        "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during convolution.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        self.image = image\n",
        "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
        "        patches = np.empty((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_size, self.kernel_size))\n",
        "        for h in range(image_h-self.kernel_size+1):\n",
        "            for w in range(image_w-self.kernel_size+1):\n",
        "                patches[h, w] = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
        "        return patches\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        \"\"\"\n",
        "        Perform forward propagation for the convolutional layer.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        # Initialize the convolution output volume of the correct size\n",
        "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
        "        # Unpack the generator\n",
        "        patches = self.patches_generator(image)\n",
        "        block_size = (16, 16)\n",
        "        grid_size = (math.ceil(convolution_output.shape[1] / block_size[0]),\n",
        "                     math.ceil(convolution_output.shape[0] / block_size[1]))\n",
        "        cnn_forward_kernel[grid_size, block_size](patches, self.kernels, convolution_output)\n",
        "        cuda.synchronize()\n",
        "        return convolution_output\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically max pooling layer.\n",
        "        It updates the kernels' weights\n",
        "        \"\"\"\n",
        "        # Initialize gradient of the loss function with respect to the kernel weights\n",
        "        dE_dk = np.zeros(self.kernels.shape)\n",
        "        patches = self.patches_generator(self.image)\n",
        "        block_size = (16, 4, 4)\n",
        "        grid_size = (math.ceil(dE_dk.shape[2] / block_size[0]),\n",
        "                     math.ceil(dE_dk.shape[1] / block_size[1]),\n",
        "                     math.ceil(dE_dk.shape[0] / block_size[2]))\n",
        "        cnn_backward_kernel[grid_size, block_size](patches, dE_dY, dE_dk)\n",
        "        cuda.synchronize()\n",
        "        # Update the parameters\n",
        "        self.kernels -= alpha*dE_dk\n",
        "        return dE_dk\n",
        "\n",
        "\n",
        "class MaxPoolingLayer:\n",
        "    def __init__(self, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the size of the kernel\n",
        "        \"\"\"\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1] // self.kernel_size\n",
        "        self.image = image\n",
        "\n",
        "        for h in range(output_h):\n",
        "            for w in range(output_w):\n",
        "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
        "                yield patch, h, w\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
        "        for patch, h, w in self.patches_generator(image):\n",
        "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1)) # Chia nhỏ để tìm số lớn nhất song song sau đó so sánh với nhau\n",
        "        return max_pooling_output\n",
        "\n",
        "    def back_prop(self, dE_dY):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk = np.zeros(self.image.shape)\n",
        "        for patch,h,w in self.patches_generator(self.image):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "\n",
        "            for idx_h in range(image_h):\n",
        "                for idx_w in range(image_w):\n",
        "                    for idx_k in range(num_kernels):\n",
        "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
        "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
        "            return dE_dk\n",
        "\n",
        "\n",
        "class SoftmaxLayer:\n",
        "    \"\"\"\n",
        "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_units, output_units):\n",
        "        # Initiallize weights and biases\n",
        "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
        "        self.bias = np.zeros(output_units)\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "      self.original_shape = image.shape # stored for backprop\n",
        "      # Flatten the image\n",
        "      #print(\"image: \", image)\n",
        "      image_flattened = image.flatten()\n",
        "      #print(\"image_flattened: \", image_flattened)\n",
        "      self.flattened_input = image_flattened # stored for backprop\n",
        "\n",
        "      # Perform matrix multiplication and add bias\n",
        "      C = np.empty(10)\n",
        "      dA = cuda.to_device(image_flattened)\n",
        "      dB = cuda.to_device(self.weight)\n",
        "      dC = cuda.to_device(C)\n",
        "      dot[(self.weight.shape[0]+255)//256, 256](dA,dB,dC)\n",
        "      #cu_matrix_vector[(dZ_dX.shape[0]+511)//512, 512](dZ_dX,dE_dZ,C)\n",
        "      result = dC.copy_to_host()\n",
        "      first_output = result  + self.bias\n",
        "      self.output = first_output\n",
        "      # Apply softmax activation\n",
        "      softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
        "\n",
        "      return softmax_output\n",
        "\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "      for i, gradient in enumerate(dE_dY):\n",
        "        if gradient == 0:\n",
        "          continue\n",
        "        transformation_eq = np.exp(self.output)\n",
        "        S_total = np.sum(transformation_eq)\n",
        "\n",
        "        # Compute gradients with respect to output (Z)\n",
        "        dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
        "        dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "\n",
        "        # Compute gradients of output Z with respect to weight, bias, input\n",
        "        dZ_dw = self.flattened_input\n",
        "        dZ_db = 1\n",
        "        dZ_dX = self.weight\n",
        "\n",
        "        # Gradient of loss with respect ot output\n",
        "        dE_dZ = gradient * dY_dZ\n",
        "\n",
        "        # Gradient of loss with respect to weight, bias, input\n",
        "\n",
        "        #C = np.empty((dZ_dw[np.newaxis].T.shape[0], dE_dZ[np.newaxis].shape[1]))\n",
        "        #dA = cuda.to_device(dZ_dw[np.newaxis].T)\n",
        "        #dB = cuda.to_device(dE_dZ[np.newaxis])\n",
        "        #dC = cuda.to_device(C)\n",
        "        #blockx = int(np.ceil(C.shape[0] / 16))\n",
        "        #blocky = int(np.ceil(C.shape[1] / 16))\n",
        "        #blockspergrid = (blockx, blocky)\n",
        "        #matmul[blockspergrid, (16,16)](dA,dB,dC)\n",
        "        #dE_dW = dC.copy_to_host()\n",
        "        dE_dW = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
        "\n",
        "        # Matrix-vector multiply function\n",
        "        C = np.empty(dZ_dX.shape[0])\n",
        "        dA = cuda.to_device(dZ_dX)\n",
        "        dB = cuda.to_device(dE_dZ)\n",
        "        dC = cuda.to_device(C)\n",
        "        cu_matrix_vector[(dZ_dX.shape[0]+15)//16, 16](dA,dB,dC)\n",
        "        dE_dX = dC.copy_to_host()\n",
        "\n",
        "       # dE_dX = dZ_dX @ dE_dZ\n",
        "\n",
        "        # Update parameters\n",
        "        self.weight -= alpha * dE_dW\n",
        "        self.bias -= alpha * (dE_dZ * dZ_db)\n",
        "\n",
        "        return dE_dX.reshape(self.original_shape)\n",
        "\n",
        "def CNN_forward(image, label, layers):\n",
        "    output = image/255.\n",
        "    for layer in layers:\n",
        "        output = layer.forward_prop(output)\n",
        "    # Compute loss (cross-entropy) and accuracy\n",
        "    loss = -np.log(output[label])\n",
        "    accuracy = 1 if np.argmax(output) == label else 0\n",
        "    return output, loss, accuracy\n",
        "\n",
        "def CNN_backprop(gradient, layers, alpha=0.05):\n",
        "    grad_back = gradient\n",
        "    for layer in layers[::-1]:\n",
        "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
        "            grad_back = layer.back_prop(grad_back, alpha)\n",
        "        elif type(layer) == MaxPoolingLayer:\n",
        "            grad_back = layer.back_prop(grad_back)\n",
        "    return grad_back\n",
        "\n",
        "\n",
        "def CNN_training(image, label, layers, alpha=0.05):\n",
        "    # Forward step\n",
        "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
        "\n",
        "    # Initial gradient\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1/output[label]\n",
        "\n",
        "    # Backprop step\n",
        "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "5VK4gXE3w-Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function"
      ],
      "metadata": {
        "id": "dWYqMGGUZjGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train function"
      ],
      "metadata": {
        "id": "1YKXC0Rljm2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(network, X_train, y_train, epochs = 1, learning_rate = 0.05, verbose = True):\n",
        "    for epoch in range(1):\n",
        "        if verbose == True:\n",
        "            print('Epoch {} ->'.format(epoch+1))\n",
        "        # Shuffle training data\n",
        "        permutation = np.random.permutation(len(X_train))\n",
        "        X_train = X_train[permutation]\n",
        "        y_train = y_train[permutation]\n",
        "        # Training the CNN\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "        for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
        "            if i % 100 == 0: # Every 100 examples\n",
        "                if verbose == True:\n",
        "                    print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
        "                loss = 0\n",
        "                accuracy = 0\n",
        "            loss_1, accuracy_1 = CNN_training(image, label, network)\n",
        "            loss += loss_1\n",
        "            accuracy += accuracy_1"
      ],
      "metadata": {
        "id": "5_mA6IhAQrEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict & Evaluate function"
      ],
      "metadata": {
        "id": "wa_FDwW3jslW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(network, image):\n",
        "    output = image/255.\n",
        "    for layer in network:\n",
        "        output = layer.forward_prop(output)\n",
        "    return np.argmax(output) # return a number\n",
        "def evaluate(network, X_test, y_test):\n",
        "    correct = 0\n",
        "    for x, y in zip(X_test, y_test):\n",
        "        pred = predict(network, x)\n",
        "        if y == pred:\n",
        "            correct += 1\n",
        "    acc = correct / y_test.shape[0]\n",
        "    print(f'Accuracy for the test set is {acc *100}')"
      ],
      "metadata": {
        "id": "Lta9bV4iQx32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading train data and define network layers\n"
      ],
      "metadata": {
        "id": "aOOaJp_Oj3wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
        "    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)\n",
        "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
        "    ]\n",
        "\n",
        "# Load training data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train[:10000]\n",
        "y_train = y_train[:10000]"
      ],
      "metadata": {
        "id": "0OaYdNsHWnjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training CNN and calculating running time"
      ],
      "metadata": {
        "id": "Wolseb1OkAqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(network, X_train, y_train, epochs=1, learning_rate=0.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N8p_68OQ-CX",
        "outputId": "f1dc3cce-5cc4-4408-90f0-ad82f40f4417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ->\n",
            "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 11 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 101. For the last 100 steps: average loss 1.776173468240187, accuracy 41\n",
            "Step 201. For the last 100 steps: average loss 1.0301337541514446, accuracy 71\n",
            "Step 301. For the last 100 steps: average loss 0.9215181353443345, accuracy 72\n",
            "Step 401. For the last 100 steps: average loss 0.8613768218258417, accuracy 65\n",
            "Step 501. For the last 100 steps: average loss 0.6160913848196516, accuracy 79\n",
            "Step 601. For the last 100 steps: average loss 0.6901168087974813, accuracy 75\n",
            "Step 701. For the last 100 steps: average loss 0.6266961758979758, accuracy 78\n",
            "Step 801. For the last 100 steps: average loss 0.4763443922646882, accuracy 86\n",
            "Step 901. For the last 100 steps: average loss 0.47970345485721955, accuracy 85\n",
            "Step 1001. For the last 100 steps: average loss 0.6071081963325514, accuracy 82\n",
            "Step 1101. For the last 100 steps: average loss 0.5319339630609468, accuracy 83\n",
            "Step 1201. For the last 100 steps: average loss 0.3569637767585578, accuracy 90\n",
            "Step 1301. For the last 100 steps: average loss 0.44105907286730495, accuracy 85\n",
            "Step 1401. For the last 100 steps: average loss 0.7809608348404321, accuracy 72\n",
            "Step 1501. For the last 100 steps: average loss 0.5341780171401262, accuracy 88\n",
            "Step 1601. For the last 100 steps: average loss 0.42850391596993626, accuracy 87\n",
            "Step 1701. For the last 100 steps: average loss 0.4789452233008202, accuracy 90\n",
            "Step 1801. For the last 100 steps: average loss 0.3934823152503816, accuracy 86\n",
            "Step 1901. For the last 100 steps: average loss 0.3499849790104699, accuracy 89\n",
            "Step 2001. For the last 100 steps: average loss 0.5072785497698196, accuracy 81\n",
            "Step 2101. For the last 100 steps: average loss 0.44488838282008303, accuracy 88\n",
            "Step 2201. For the last 100 steps: average loss 0.4507256758067137, accuracy 84\n",
            "Step 2301. For the last 100 steps: average loss 0.40825548040184484, accuracy 86\n",
            "Step 2401. For the last 100 steps: average loss 0.3495671080920166, accuracy 91\n",
            "Step 2501. For the last 100 steps: average loss 0.3735970891265539, accuracy 88\n",
            "Step 2601. For the last 100 steps: average loss 0.2552100975314755, accuracy 92\n",
            "Step 2701. For the last 100 steps: average loss 0.3130986078827153, accuracy 88\n",
            "Step 2801. For the last 100 steps: average loss 0.40354554503407014, accuracy 87\n",
            "Step 2901. For the last 100 steps: average loss 0.41335196453745615, accuracy 88\n",
            "Step 3001. For the last 100 steps: average loss 0.24730619371029242, accuracy 93\n",
            "Step 3101. For the last 100 steps: average loss 0.3825903056508784, accuracy 89\n",
            "Step 3201. For the last 100 steps: average loss 0.3324568970477672, accuracy 88\n",
            "Step 3301. For the last 100 steps: average loss 0.42678179491240537, accuracy 87\n",
            "Step 3401. For the last 100 steps: average loss 0.3065243468230471, accuracy 89\n",
            "Step 3501. For the last 100 steps: average loss 0.3985291600801991, accuracy 90\n",
            "Step 3601. For the last 100 steps: average loss 0.5546577052227213, accuracy 82\n",
            "Step 3701. For the last 100 steps: average loss 0.3418897976795609, accuracy 92\n",
            "Step 3801. For the last 100 steps: average loss 0.497046363337928, accuracy 83\n",
            "Step 3901. For the last 100 steps: average loss 0.18363114093869817, accuracy 95\n",
            "Step 4001. For the last 100 steps: average loss 0.24673851361630345, accuracy 94\n",
            "Step 4101. For the last 100 steps: average loss 0.47150877292801774, accuracy 85\n",
            "Step 4201. For the last 100 steps: average loss 0.44856770692534126, accuracy 86\n",
            "Step 4301. For the last 100 steps: average loss 0.2500941306371527, accuracy 95\n",
            "Step 4401. For the last 100 steps: average loss 0.2532541292481081, accuracy 93\n",
            "Step 4501. For the last 100 steps: average loss 0.3670410051455761, accuracy 90\n",
            "Step 4601. For the last 100 steps: average loss 0.4507219655575067, accuracy 87\n",
            "Step 4701. For the last 100 steps: average loss 0.5296701369389941, accuracy 86\n",
            "Step 4801. For the last 100 steps: average loss 0.2187718411135544, accuracy 95\n",
            "Step 4901. For the last 100 steps: average loss 0.204126230435074, accuracy 95\n",
            "Step 5001. For the last 100 steps: average loss 0.3260514615125472, accuracy 89\n",
            "Step 5101. For the last 100 steps: average loss 0.3399193957393525, accuracy 90\n",
            "Step 5201. For the last 100 steps: average loss 0.2922537657280989, accuracy 92\n",
            "Step 5301. For the last 100 steps: average loss 0.5021348611240125, accuracy 84\n",
            "Step 5401. For the last 100 steps: average loss 0.42172359248263475, accuracy 92\n",
            "Step 5501. For the last 100 steps: average loss 0.3478082724047406, accuracy 88\n",
            "Step 5601. For the last 100 steps: average loss 0.30512907911027176, accuracy 92\n",
            "Step 5701. For the last 100 steps: average loss 0.3330828593644727, accuracy 93\n",
            "Step 5801. For the last 100 steps: average loss 0.2611794694828879, accuracy 90\n",
            "Step 5901. For the last 100 steps: average loss 0.30636660181709396, accuracy 93\n",
            "Step 6001. For the last 100 steps: average loss 0.3102762689070867, accuracy 92\n",
            "Step 6101. For the last 100 steps: average loss 0.33877500025545737, accuracy 86\n",
            "Step 6201. For the last 100 steps: average loss 0.3378326454652708, accuracy 88\n",
            "Step 6301. For the last 100 steps: average loss 0.22353155782367434, accuracy 92\n",
            "Step 6401. For the last 100 steps: average loss 0.6168982690216914, accuracy 82\n",
            "Step 6501. For the last 100 steps: average loss 0.2966045140888019, accuracy 93\n",
            "Step 6601. For the last 100 steps: average loss 0.5861232063029455, accuracy 85\n",
            "Step 6701. For the last 100 steps: average loss 0.35053219372672073, accuracy 86\n",
            "Step 6801. For the last 100 steps: average loss 0.3155821979177282, accuracy 89\n",
            "Step 6901. For the last 100 steps: average loss 0.4234154956552723, accuracy 88\n",
            "Step 7001. For the last 100 steps: average loss 0.5015152670891383, accuracy 84\n",
            "Step 7101. For the last 100 steps: average loss 0.15781862723336754, accuracy 95\n",
            "Step 7201. For the last 100 steps: average loss 0.23967638372530584, accuracy 93\n",
            "Step 7301. For the last 100 steps: average loss 0.4941828189915487, accuracy 84\n",
            "Step 7401. For the last 100 steps: average loss 0.23125238281595298, accuracy 92\n",
            "Step 7501. For the last 100 steps: average loss 0.39491067918452566, accuracy 90\n",
            "Step 7601. For the last 100 steps: average loss 0.4022148842285019, accuracy 91\n",
            "Step 7701. For the last 100 steps: average loss 0.21147521234082692, accuracy 95\n",
            "Step 7801. For the last 100 steps: average loss 0.3512670828954089, accuracy 88\n",
            "Step 7901. For the last 100 steps: average loss 0.40991285953758955, accuracy 88\n",
            "Step 8001. For the last 100 steps: average loss 0.28827786452587545, accuracy 89\n",
            "Step 8101. For the last 100 steps: average loss 0.3050277007996371, accuracy 91\n",
            "Step 8201. For the last 100 steps: average loss 0.3327000148434462, accuracy 91\n",
            "Step 8301. For the last 100 steps: average loss 0.3754101857239867, accuracy 92\n",
            "Step 8401. For the last 100 steps: average loss 0.33232478046874925, accuracy 94\n",
            "Step 8501. For the last 100 steps: average loss 0.2316818503834005, accuracy 93\n",
            "Step 8601. For the last 100 steps: average loss 0.37917729892771135, accuracy 88\n",
            "Step 8701. For the last 100 steps: average loss 0.24552866318746236, accuracy 93\n",
            "Step 8801. For the last 100 steps: average loss 0.314173376507887, accuracy 90\n",
            "Step 8901. For the last 100 steps: average loss 0.4149991466904005, accuracy 85\n",
            "Step 9001. For the last 100 steps: average loss 0.3550903571768716, accuracy 92\n",
            "Step 9101. For the last 100 steps: average loss 0.27272325392630437, accuracy 91\n",
            "Step 9201. For the last 100 steps: average loss 0.44768377943966414, accuracy 86\n",
            "Step 9301. For the last 100 steps: average loss 0.3341577544518437, accuracy 92\n",
            "Step 9401. For the last 100 steps: average loss 0.313528337505501, accuracy 93\n",
            "Step 9501. For the last 100 steps: average loss 0.2031629028405741, accuracy 94\n",
            "Step 9601. For the last 100 steps: average loss 0.28329065895415906, accuracy 94\n",
            "Step 9701. For the last 100 steps: average loss 0.22034418068368627, accuracy 95\n",
            "Step 9801. For the last 100 steps: average loss 0.36700590057348104, accuracy 88\n",
            "Step 9901. For the last 100 steps: average loss 0.2845487894935282, accuracy 93\n",
            "CPU times: user 1min 31s, sys: 1.03 s, total: 1min 32s\n",
            "Wall time: 1min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict for 10000 images and find the accuracy"
      ],
      "metadata": {
        "id": "lnIg4t1Tle7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(network, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ-lLypJXFLX",
        "outputId": "f0e91420-edb6-48a4-f402-f9aa9146ebd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for the test set is 91.67999999999999\n"
          ]
        }
      ]
    }
  ]
}