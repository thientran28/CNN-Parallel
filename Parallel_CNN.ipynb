{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "eCJPlUdVcpzz",
        "outputId": "95612d39-d0b2-4899-eeaa-8658b59f9b5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n#Test the convolutions with 1 image, to put in the article\\n# Test\\ndf_train = pd.read_csv('train.csv')\\nimg = df_train.iloc[40,:].values[1:]\\nimg = np.reshape(img,(28,28))\\nplt.imshow(img, cmap='gray')\\nplt.show()\\nprint(img.shape)\\nplt.savefig('images/original_image.png', format='png', dpi=1200)\\n\\n# Test with a convolution of 16 filters of size 3x3\\nmy_conv = ConvolutionLayer(32,3)\\noutput = my_conv.forward_prop(img)\\n# See the dimensions of the output volume, they follow the usual formula\\nprint(output.shape)\\n\\n# Plot 16th volume after the convolution\\nplt.imshow(output[:,:,15], cmap='gray')\\nplt.show()\\nplt.savefig('images/image_convolved.png', format='png', dpi=1200)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import jit, prange\n",
        "from numba import config\n",
        "from numba import jit, cuda\n",
        "#config.THREADING_LAYER = 'omp'\n",
        "\n",
        "class ConvolutionLayer:\n",
        "    def __init__(self, kernel_num, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
        "        \"\"\"\n",
        "        self.kernel_num = kernel_num\n",
        "        self.kernel_size = kernel_size\n",
        "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization\n",
        "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during convolution.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        self.image = image\n",
        "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
        "        patches = np.empty((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_size, self.kernel_size))\n",
        "        for h in range(image_h-self.kernel_size+1):\n",
        "            for w in range(image_w-self.kernel_size+1):\n",
        "                patches[h, w] = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
        "        return patches\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        \"\"\"\n",
        "        Perform forward propagation for the convolutional layer.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        # Initialize the convolution output volume of the correct size\n",
        "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
        "        # Unpack the generator\n",
        "        patches = self.patches_generator(image)\n",
        "        block_size = (16, 16)\n",
        "        grid_size = (math.ceil(convolution_output.shape[1] / block_size[0]),\n",
        "                     math.ceil(convolution_output.shape[0] / block_size[1]))\n",
        "        cnn_forward_kernel[grid_size, block_size](patches, self.kernels, convolution_output)\n",
        "        cuda.synchronize()\n",
        "        return convolution_output\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically max pooling layer.\n",
        "        It updates the kernels' weights\n",
        "        \"\"\"\n",
        "        # Initialize gradient of the loss function with respect to the kernel weights\n",
        "        dE_dk = np.zeros(self.kernels.shape)\n",
        "        patches = self.patches_generator(self.image)\n",
        "        block_size = (16, 4, 4)\n",
        "        grid_size = (math.ceil(dE_dk.shape[2] / block_size[0]),\n",
        "                     math.ceil(dE_dk.shape[1] / block_size[1]),\n",
        "                     math.ceil(dE_dk.shape[0] / block_size[2]))\n",
        "        cnn_backward_kernel[grid_size, block_size](patches, dE_dY, dE_dk)\n",
        "        cuda.synchronize()\n",
        "        # Update the parameters\n",
        "        self.kernels -= alpha*dE_dk\n",
        "        return dE_dk\n",
        "\n",
        "\n",
        "class MaxPoolingLayer:\n",
        "    def __init__(self, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the size of the kernel\n",
        "        \"\"\"\n",
        "        self.kernel_size = kernel_size\n",
        "    @cuda.jit\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1] // self.kernel_size\n",
        "        self.image = image\n",
        "        c,r=cuda.grid(2)\n",
        "        if r < output_h and c < output_w:\n",
        "              patch = image[(r*self.kernel_size):(r*self.kernel_size+self.kernel_size), (c*self.kernel_size):(c*self.kernel_size+self.kernel_size)]\n",
        "              yield patch, r, c\n",
        "\n",
        "    @cuda.jit\n",
        "    def forward_prop(self, image):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
        "        c,r=cuda.grid(2)\n",
        "        block_size = (32, 32)\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1]\n",
        "        grid_size = (math.ceil(image.shape[1] / block_size[0]),\n",
        "             math.ceil(image.shape[0] / block_size[1]))\n",
        "        if r < output_h and c < output_w:\n",
        "            for patch, r, c in self.patches_generator[grid_size, block_size](image):\n",
        "                max_pooling_output[r,c] = np.amax(patch, axis=(0,1))\n",
        "            return max_pooling_output\n",
        "\n",
        "\n",
        "    def back_prop(self, dE_dY):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk = np.zeros(self.image.shape)\n",
        "        for patch,h,w in self.patches_generator(self.image):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "\n",
        "            for idx_h in range(image_h):\n",
        "                for idx_w in range(image_w):\n",
        "                    for idx_k in range(num_kernels):\n",
        "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
        "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
        "            return dE_dk\n",
        "\n",
        "class SoftmaxLayer:\n",
        "    \"\"\"\n",
        "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_units, output_units):\n",
        "        # Initiallize weights and biases\n",
        "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
        "        self.bias = np.zeros(output_units)\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "      self.original_shape = image.shape # stored for backprop\n",
        "      # Flatten the image\n",
        "      #print(\"image: \", image)\n",
        "      image_flattened = image.flatten()\n",
        "      #print(\"image_flattened: \", image_flattened)\n",
        "      self.flattened_input = image_flattened # stored for backprop\n",
        "\n",
        "      # Perform matrix multiplication and add bias\n",
        "      C = np.empty(10)\n",
        "      dA = cuda.to_device(image_flattened)\n",
        "      dB = cuda.to_device(self.weight)\n",
        "      dC = cuda.to_device(C)\n",
        "      dot[(self.weight.shape[0]+255)//256, 256](dA,dB,dC)\n",
        "      #cu_matrix_vector[(dZ_dX.shape[0]+511)//512, 512](dZ_dX,dE_dZ,C)\n",
        "      result = dC.copy_to_host()\n",
        "      first_output = result  + self.bias\n",
        "      self.output = first_output\n",
        "      # Apply softmax activation\n",
        "      softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
        "\n",
        "      return softmax_output\n",
        "\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "      for i, gradient in enumerate(dE_dY):\n",
        "        if gradient == 0:\n",
        "          continue\n",
        "        transformation_eq = np.exp(self.output)\n",
        "        S_total = np.sum(transformation_eq)\n",
        "\n",
        "        # Compute gradients with respect to output (Z)\n",
        "        dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
        "        dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "\n",
        "        # Compute gradients of output Z with respect to weight, bias, input\n",
        "        dZ_dw = self.flattened_input\n",
        "        dZ_db = 1\n",
        "        dZ_dX = self.weight\n",
        "\n",
        "        # Gradient of loss with respect ot output\n",
        "        dE_dZ = gradient * dY_dZ\n",
        "\n",
        "        # Gradient of loss with respect to weight, bias, input\n",
        "        dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
        "        dE_db = dE_dZ * dZ_db\n",
        "\n",
        "        # Matrix-vector multiply function\n",
        "        C = np.empty(dZ_dX.shape[0])\n",
        "        dA = cuda.to_device(dZ_dX)\n",
        "        dB = cuda.to_device(dE_dZ)\n",
        "        dC = cuda.to_device(C)\n",
        "        cu_matrix_vector[(dZ_dX.shape[0]+127)//128, 128](dA,dB,dC)\n",
        "        dE_dX = dC.copy_to_host()\n",
        "\n",
        "        # Update parameters\n",
        "        self.weight -= alpha* (dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis])\n",
        "        self.bias -= alpha * (dE_dZ * dZ_db)\n",
        "\n",
        "        return dE_dX.reshape(self.original_shape)\n",
        "\n",
        "\n",
        "def CNN_backprop(gradient, layers,image_backprob_max, alpha=0.05):\n",
        "    grad_back = gradient\n",
        "    for layer in layers[::-1]:\n",
        "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
        "            grad_back = layer.back_prop(grad_back, alpha)\n",
        "        elif type(layer) == MaxPoolingLayer:\n",
        "            grad_back = back_prop(image_backprob_max,grad_back,kernel_size=2)\n",
        "    return grad_back\n",
        "\n",
        "\n",
        "def CNN_training(image, label, layers, alpha=0.05):\n",
        "    # Forward step\n",
        "    output, loss, accuracy,image_backprob_max = CNN_forward(image, label, layers)\n",
        "\n",
        "    # Initial gradient\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1/output[label]\n",
        "\n",
        "    # Backprop step\n",
        "    gradient_back = CNN_backprop(gradient, layers,image_backprob_max, alpha)\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#Test the convolutions with 1 image, to put in the article\n",
        "# Test\n",
        "df_train = pd.read_csv('train.csv')\n",
        "img = df_train.iloc[40,:].values[1:]\n",
        "img = np.reshape(img,(28,28))\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "plt.savefig('images/original_image.png', format='png', dpi=1200)\n",
        "\n",
        "# Test with a convolution of 16 filters of size 3x3\n",
        "my_conv = ConvolutionLayer(32,3)\n",
        "output = my_conv.forward_prop(img)\n",
        "# See the dimensions of the output volume, they follow the usual formula\n",
        "print(output.shape)\n",
        "\n",
        "# Plot 16th volume after the convolution\n",
        "plt.imshow(output[:,:,15], cmap='gray')\n",
        "plt.show()\n",
        "plt.savefig('images/image_convolved.png', format='png', dpi=1200)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5v1zUu5wY1Yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Parallell Convoluner Layer v1:"
      ],
      "metadata": {
        "id": "oYTM62eTY1af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def cnn_forward_kernel(patches, kernels, convolution_output):\n",
        "    r, c = cuda.grid(2)\n",
        "\n",
        "    if r < patches.shape[0] and c < patches.shape[1]:\n",
        "        for k in range(kernels.shape[0]):\n",
        "            sum = 0\n",
        "            for i in range(kernels.shape[1]):\n",
        "                for j in range(kernels.shape[2]):\n",
        "                    sum += patches[r, c, i, j] * kernels[k, i, j]\n",
        "            convolution_output[r, c, k] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def cnn_backward_kernel(patches, dE_dY, dE_dk):\n",
        "    x, y, z = cuda.grid(3)\n",
        "\n",
        "    if x < dE_dk.shape[0] and y < dE_dk.shape[1] and z < dE_dk.shape[2]:\n",
        "        temp = 0\n",
        "        for h in range(patches.shape[0]):\n",
        "            for w in range(patches.shape[1]):\n",
        "                temp += patches[h, w, y, z] * dE_dY[h, w, x]\n",
        "        dE_dk[x, y, z] = temp"
      ],
      "metadata": {
        "id": "rooLF511owYL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Sz09moCZTXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Parallell Max Pooling Layer v1:"
      ],
      "metadata": {
        "id": "K05mzy-EZTZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@cuda.jit(device=True)\n",
        "def patches_generator(image,kernel_size):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // kernel_size\n",
        "        output_w = image.shape[1] // kernel_size\n",
        "        #self.image = image\n",
        "        #c,r=cuda.grid(2)\n",
        "        for h in range(output_h):\n",
        "            for w in range(output_w):\n",
        "                patch = image[(h*kernel_size):(h*kernel_size+kernel_size), (w*kernel_size):(w*kernel_size+kernel_size)]\n",
        "                yield patch,h,w\n",
        "\n",
        "def forward_prop(image,kernel_size):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//kernel_size, image_w//kernel_size, num_kernels))\n",
        "        for patch, h, w in patches_generator(image,kernel_size):\n",
        "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
        "        return max_pooling_output\n",
        "\n",
        "\n",
        "\n",
        "def back_prop(image,dE_dY,kernel_size):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk_temp1 = np.zeros(image.shape)\n",
        "        #dE_dk=np.ascontiguousarray(dE_dk_temp1)\n",
        "        #cuda.pinned(dE_dk)\n",
        "        for patch,h,w in patches_generator(image,kernel_size):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "            block_size = (16, 16)\n",
        "            grid_size = (math.ceil(image_w / block_size[0]),\n",
        "                        math.ceil(image_h / block_size[1]))\n",
        "            patch=np.ascontiguousarray(patch)\n",
        "\n",
        "            dA=cuda.to_device(patch)\n",
        "            dE=cuda.to_device(dE_dk_temp1)\n",
        "            back_prob_sup[grid_size, block_size](image_h,image_w,num_kernels,dA,max_val,dE_dY,dE,h,w,kernel_size)\n",
        "            dE_dk=dE.copy_to_host()\n",
        "            return dE_dk\n",
        "\n",
        "@cuda.jit\n",
        "def back_prob_sup(image_h,image_w,num_kernels,patch,max_val,dE_dY,dE_dk,h,w,kernel_size):\n",
        "    c,r=cuda.grid(2)\n",
        "    #print(\"hihi\")\n",
        "    if r < image_h and c < image_w:\n",
        "          for idx_k in range(num_kernels):\n",
        "                if patch[r,c,idx_k] == max_val[idx_k]:\n",
        "                  #print(\"hihi\")\n",
        "                  dE_dk[h*kernel_size+r, w*kernel_size+c, idx_k] = dE_dY[h,w,idx_k]\n",
        "    #return dE_dk"
      ],
      "metadata": {
        "id": "2mLxP8vGcrJk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Parallell Soft max Layer v1:"
      ],
      "metadata": {
        "id": "w27ap-PUZJPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def dot(a, b, c):\n",
        "  col = cuda.grid(1)\n",
        "  if (col < b.shape[1]):\n",
        "    sum = 0.0\n",
        "    for i in range(b.shape[0]):\n",
        "      sum += a[i] * b[i, col]\n",
        "    c[col] = sum\n",
        "\n",
        "@cuda.jit\n",
        "def cu_matrix_vector(A, b, c):\n",
        "  row = cuda.grid(1)\n",
        "  if (row < A.shape[0]):\n",
        "    sum = 0.0\n",
        "    for i in range(A.shape[1]):\n",
        "      sum += A[row, i] * b[i]\n",
        "    c[row] = sum\n"
      ],
      "metadata": {
        "id": "LOVIFj25zufr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function"
      ],
      "metadata": {
        "id": "dWYqMGGUZjGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numba import cuda\n",
        "#from utils import *\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "def main():\n",
        "  # Load training data\n",
        "  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  X_train = X_train[:10000]\n",
        "  y_train = y_train[:10000]\n",
        "\n",
        "  # Define the network\n",
        "  layers = [\n",
        "    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
        "    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)\n",
        "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
        "    ]\n",
        "\n",
        "  for epoch in range(1):\n",
        "    print('Epoch {} ->'.format(epoch+1))\n",
        "    # Shuffle training data\n",
        "    permutation = np.random.permutation(len(X_train))\n",
        "    X_train = X_train[permutation]\n",
        "    y_train = y_train[permutation]\n",
        "    # Training the CNN\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
        "      if i % 100 == 0: # Every 100 examples\n",
        "        print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "      image_backprob_max=image\n",
        "      loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
        "      loss += loss_1\n",
        "      accuracy += accuracy_1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  start = time.time()\n",
        "  main()\n",
        "  end = time.time()\n",
        "  print(f'Processing time: {end - start} s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBDS6JnLcy2t",
        "outputId": "1f1b82cd-1a01-425b-e81c-8990987475bd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ->\n",
            "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 11 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 22 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 101. For the last 100 steps: average loss 1.8925837771217817, accuracy 45\n",
            "Step 201. For the last 100 steps: average loss 1.1287192406288464, accuracy 67\n",
            "Step 301. For the last 100 steps: average loss 0.8818340505745351, accuracy 75\n",
            "Step 401. For the last 100 steps: average loss 0.862956792400424, accuracy 74\n",
            "Step 501. For the last 100 steps: average loss 0.828615802422499, accuracy 77\n",
            "Step 601. For the last 100 steps: average loss 0.6318904278544415, accuracy 77\n",
            "Step 701. For the last 100 steps: average loss 0.4708180346597755, accuracy 85\n",
            "Step 801. For the last 100 steps: average loss 0.5787393996887817, accuracy 87\n",
            "Step 901. For the last 100 steps: average loss 0.5986817872194977, accuracy 85\n",
            "Step 1001. For the last 100 steps: average loss 0.5136441680674542, accuracy 84\n",
            "Step 1101. For the last 100 steps: average loss 0.7196458118158945, accuracy 77\n",
            "Step 1201. For the last 100 steps: average loss 0.5424029477059772, accuracy 82\n",
            "Step 1301. For the last 100 steps: average loss 0.34974725501618337, accuracy 91\n",
            "Step 1401. For the last 100 steps: average loss 0.46974454257270165, accuracy 84\n",
            "Step 1501. For the last 100 steps: average loss 0.4497964919108373, accuracy 88\n",
            "Step 1601. For the last 100 steps: average loss 0.5194973606673121, accuracy 86\n",
            "Step 1701. For the last 100 steps: average loss 0.3881331504104895, accuracy 87\n",
            "Step 1801. For the last 100 steps: average loss 0.3169639777672019, accuracy 91\n",
            "Step 1901. For the last 100 steps: average loss 0.43288923920050415, accuracy 89\n",
            "Step 2001. For the last 100 steps: average loss 0.3838005622433514, accuracy 90\n",
            "Step 2101. For the last 100 steps: average loss 0.546058657011987, accuracy 89\n",
            "Step 2201. For the last 100 steps: average loss 0.6501189457200315, accuracy 76\n",
            "Step 2301. For the last 100 steps: average loss 0.3906957793201228, accuracy 87\n",
            "Step 2401. For the last 100 steps: average loss 0.3440516490888409, accuracy 89\n",
            "Step 2501. For the last 100 steps: average loss 0.4012816787000275, accuracy 87\n",
            "Step 2601. For the last 100 steps: average loss 0.27447637964834626, accuracy 92\n",
            "Step 2701. For the last 100 steps: average loss 0.29420505446357764, accuracy 93\n",
            "Step 2801. For the last 100 steps: average loss 0.3340304225881256, accuracy 90\n",
            "Step 2901. For the last 100 steps: average loss 0.4103398074382211, accuracy 92\n",
            "Step 3001. For the last 100 steps: average loss 0.45449695855765343, accuracy 85\n",
            "Step 3101. For the last 100 steps: average loss 0.2965028932295553, accuracy 91\n",
            "Step 3201. For the last 100 steps: average loss 0.3325185512091447, accuracy 89\n",
            "Step 3301. For the last 100 steps: average loss 0.3824403024822386, accuracy 91\n",
            "Step 3401. For the last 100 steps: average loss 0.27102155367045105, accuracy 94\n",
            "Step 3501. For the last 100 steps: average loss 0.4253654085363703, accuracy 87\n",
            "Step 3601. For the last 100 steps: average loss 0.3351107382697449, accuracy 91\n",
            "Step 3701. For the last 100 steps: average loss 0.2349084704928419, accuracy 94\n",
            "Step 3801. For the last 100 steps: average loss 0.5260015498581078, accuracy 83\n",
            "Step 3901. For the last 100 steps: average loss 0.27245995988734106, accuracy 93\n",
            "Step 4001. For the last 100 steps: average loss 0.3302137850311388, accuracy 91\n",
            "Step 4101. For the last 100 steps: average loss 0.3654902839385188, accuracy 91\n",
            "Step 4201. For the last 100 steps: average loss 0.32231406936432483, accuracy 93\n",
            "Step 4301. For the last 100 steps: average loss 0.4279512676569336, accuracy 87\n",
            "Step 4401. For the last 100 steps: average loss 0.27739470080893175, accuracy 92\n",
            "Step 4501. For the last 100 steps: average loss 0.4330077732527519, accuracy 89\n",
            "Step 4601. For the last 100 steps: average loss 0.2586106541183309, accuracy 94\n",
            "Step 4701. For the last 100 steps: average loss 0.42332977194280097, accuracy 87\n",
            "Step 4801. For the last 100 steps: average loss 0.30857332331876086, accuracy 91\n",
            "Step 4901. For the last 100 steps: average loss 0.18517718754074683, accuracy 97\n",
            "Step 5001. For the last 100 steps: average loss 0.20481644334167817, accuracy 93\n",
            "Step 5101. For the last 100 steps: average loss 0.3380910668787458, accuracy 92\n",
            "Step 5201. For the last 100 steps: average loss 0.3131569395308007, accuracy 91\n",
            "Step 5301. For the last 100 steps: average loss 0.30874641198297087, accuracy 91\n",
            "Step 5401. For the last 100 steps: average loss 0.2414983230228132, accuracy 91\n",
            "Step 5501. For the last 100 steps: average loss 0.29420522565677787, accuracy 90\n",
            "Step 5601. For the last 100 steps: average loss 0.389657795924495, accuracy 87\n",
            "Step 5701. For the last 100 steps: average loss 0.3643589538005768, accuracy 88\n",
            "Step 5801. For the last 100 steps: average loss 0.39320649542316916, accuracy 90\n",
            "Step 5901. For the last 100 steps: average loss 0.22935146693949052, accuracy 91\n",
            "Step 6001. For the last 100 steps: average loss 0.2591618641641062, accuracy 92\n",
            "Step 6101. For the last 100 steps: average loss 0.30478399025593617, accuracy 90\n",
            "Step 6201. For the last 100 steps: average loss 0.3059355875176013, accuracy 91\n",
            "Step 6301. For the last 100 steps: average loss 0.43814621667117215, accuracy 88\n",
            "Step 6401. For the last 100 steps: average loss 0.38621092926059186, accuracy 89\n",
            "Step 6501. For the last 100 steps: average loss 0.4222987922480158, accuracy 89\n",
            "Step 6601. For the last 100 steps: average loss 0.34068013535646297, accuracy 90\n",
            "Step 6701. For the last 100 steps: average loss 0.31552372563302444, accuracy 90\n",
            "Step 6801. For the last 100 steps: average loss 0.2733710487722644, accuracy 91\n",
            "Step 6901. For the last 100 steps: average loss 0.30657991539042545, accuracy 92\n",
            "Step 7001. For the last 100 steps: average loss 0.4042277194227099, accuracy 91\n",
            "Step 7101. For the last 100 steps: average loss 0.3128654167349579, accuracy 92\n",
            "Step 7201. For the last 100 steps: average loss 0.334915845392308, accuracy 90\n",
            "Step 7301. For the last 100 steps: average loss 0.5405743605442145, accuracy 89\n",
            "Step 7401. For the last 100 steps: average loss 0.17430118722380278, accuracy 96\n",
            "Step 7501. For the last 100 steps: average loss 0.39681454523861587, accuracy 88\n",
            "Step 7601. For the last 100 steps: average loss 0.26814663092869373, accuracy 94\n",
            "Step 7701. For the last 100 steps: average loss 0.20720597294670232, accuracy 98\n",
            "Step 7801. For the last 100 steps: average loss 0.35185205592342345, accuracy 91\n",
            "Step 7901. For the last 100 steps: average loss 0.2838049292758561, accuracy 92\n",
            "Step 8001. For the last 100 steps: average loss 0.1700826421957802, accuracy 94\n",
            "Step 8101. For the last 100 steps: average loss 0.35810547204103593, accuracy 90\n",
            "Step 8201. For the last 100 steps: average loss 0.3650215637598439, accuracy 91\n",
            "Step 8301. For the last 100 steps: average loss 0.2816223955980213, accuracy 91\n",
            "Step 8401. For the last 100 steps: average loss 0.26348909294782713, accuracy 92\n",
            "Step 8501. For the last 100 steps: average loss 0.19421031706580938, accuracy 96\n",
            "Step 8601. For the last 100 steps: average loss 0.3054666976641127, accuracy 92\n",
            "Step 8701. For the last 100 steps: average loss 0.26124304193159564, accuracy 92\n",
            "Step 8801. For the last 100 steps: average loss 0.16403678715632128, accuracy 94\n",
            "Step 8901. For the last 100 steps: average loss 0.35331597843619783, accuracy 93\n",
            "Step 9001. For the last 100 steps: average loss 0.27159438528351876, accuracy 91\n",
            "Step 9101. For the last 100 steps: average loss 0.262875324330881, accuracy 94\n",
            "Step 9201. For the last 100 steps: average loss 0.18679469844538021, accuracy 95\n",
            "Step 9301. For the last 100 steps: average loss 0.3165981349430608, accuracy 92\n",
            "Step 9401. For the last 100 steps: average loss 0.1658358303079629, accuracy 96\n",
            "Step 9501. For the last 100 steps: average loss 0.38446389934803776, accuracy 88\n",
            "Step 9601. For the last 100 steps: average loss 0.25845057629249985, accuracy 92\n",
            "Step 9701. For the last 100 steps: average loss 0.34775867138297434, accuracy 92\n",
            "Step 9801. For the last 100 steps: average loss 0.3454054707254099, accuracy 90\n",
            "Step 9901. For the last 100 steps: average loss 0.21349389141487218, accuracy 94\n",
            "Processing time: 111.18359184265137 s\n"
          ]
        }
      ]
    }
  ]
}