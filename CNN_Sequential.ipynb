{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import numba\n",
        "from numba import jit, cuda\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qD4kJkUCVpEC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Layer"
      ],
      "metadata": {
        "id": "TgovtE9VZTqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3Q5qtDrGUm7t"
      },
      "outputs": [],
      "source": [
        "class ConvolutionLayer:\n",
        "    def __init__(self, kernel_num, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
        "        \"\"\"\n",
        "        self.kernel_num = kernel_num\n",
        "        self.kernel_size = kernel_size\n",
        "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization\n",
        "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during convolution.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        self.image = image\n",
        "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
        "        patches = np.empty((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_size, self.kernel_size))\n",
        "        for h in range(image_h-self.kernel_size+1):\n",
        "            for w in range(image_w-self.kernel_size+1):\n",
        "                patches[h, w] = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
        "        return patches\n",
        "    def forward_prop(self, image):\n",
        "        \"\"\"\n",
        "        Perform forward propagation for the convolutional layer.\n",
        "        \"\"\"\n",
        "        # Extract image height and width\n",
        "        image_h, image_w = image.shape\n",
        "        # Initialize the convolution output volume of the correct size\n",
        "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
        "        # Unpack the generator\n",
        "        patches = self.patches_generator(image)\n",
        "        for h in range(patches.shape[0]):\n",
        "            for w in range(patches.shape[1]):\n",
        "                # Perform convolution for each patch\n",
        "                convolution_output[h,w] = np.sum(patches[h, w]*self.kernels, axis=(1,2))\n",
        "        return convolution_output\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically max pooling layer.\n",
        "        It updates the kernels' weights\n",
        "        \"\"\"\n",
        "        # Initialize gradient of the loss function with respect to the kernel weights\n",
        "        dE_dk = np.zeros(self.kernels.shape)\n",
        "        patches = self.patches_generator(self.image)\n",
        "        for h in range(patches.shape[0]):\n",
        "            for w in range(patches.shape[1]):\n",
        "                for f in range(self.kernel_num):\n",
        "                    dE_dk[f] += patches[h, w] * dE_dY[h, w, f]\n",
        "        # Update the parameters\n",
        "        self.kernels -= alpha*dE_dk\n",
        "        return dE_dk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MaxPooling Layer"
      ],
      "metadata": {
        "id": "VXDe0GSZZZyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolingLayer:\n",
        "    def __init__(self, kernel_size):\n",
        "        \"\"\"\n",
        "        Constructor takes as input the size of the kernel\n",
        "        \"\"\"\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def patches_generator(self, image):\n",
        "        \"\"\"\n",
        "        Divide the input image in patches to be used during pooling.\n",
        "        Yields the tuples containing the patches and their coordinates.\n",
        "        \"\"\"\n",
        "        # Compute the ouput size\n",
        "        output_h = image.shape[0] // self.kernel_size\n",
        "        output_w = image.shape[1] // self.kernel_size\n",
        "        self.image = image\n",
        "\n",
        "        for h in range(output_h):\n",
        "            for w in range(output_w):\n",
        "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
        "                yield patch, h, w\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        image_h, image_w, num_kernels = image.shape\n",
        "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
        "        for patch, h, w in self.patches_generator(image):\n",
        "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
        "        return max_pooling_output\n",
        "\n",
        "    def back_prop(self, dE_dY):\n",
        "        \"\"\"\n",
        "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
        "        to the kernels' weights.\n",
        "        dE_dY comes from the following layer, typically softmax.\n",
        "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
        "        \"\"\"\n",
        "        dE_dk = np.zeros(self.image.shape)\n",
        "        for patch,h,w in self.patches_generator(self.image):\n",
        "            image_h, image_w, num_kernels = patch.shape\n",
        "            max_val = np.amax(patch, axis=(0,1))\n",
        "\n",
        "            for idx_h in range(image_h):\n",
        "                for idx_w in range(image_w):\n",
        "                    for idx_k in range(num_kernels):\n",
        "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
        "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
        "            return dE_dk\n",
        "\n",
        "def dot_product(vector1, vector2):\n",
        "    if len(vector1) != len(vector2):\n",
        "        raise ValueError(\"Vectors have the same length\")\n",
        "    dot_product = 0.0\n",
        "    for i in range(len(vector1)):\n",
        "        dot_product += vector1[i] * vector2[i]\n",
        "    return dot_product"
      ],
      "metadata": {
        "id": "5VGz0bHiVa6P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Layer"
      ],
      "metadata": {
        "id": "dBFIvn2_Zd3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SoftmaxLayer:\n",
        "    \"\"\"\n",
        "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_units, output_units):\n",
        "        # Initiallize weights and biases\n",
        "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
        "        self.bias = np.zeros(output_units)\n",
        "\n",
        "    def forward_prop(self, image):\n",
        "        self.original_shape = image.shape # stored for backprop\n",
        "        # Flatten the image\n",
        "        image_flattened = image.flatten()\n",
        "        self.flattened_input = image_flattened # stored for backprop\n",
        "        # Perform matrix multiplication and add bias\n",
        "        first_output = dot_product(image_flattened, self.weight) + self.bias\n",
        "        self.output = first_output\n",
        "        # Apply softmax activation\n",
        "        softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
        "        return softmax_output\n",
        "\n",
        "    def back_prop(self, dE_dY, alpha):\n",
        "        for i, gradient in enumerate(dE_dY):\n",
        "            if gradient == 0:\n",
        "                continue\n",
        "            transformation_eq = np.exp(self.output)\n",
        "            S_total = np.sum(transformation_eq)\n",
        "\n",
        "            # Compute gradients with respect to output (Z)\n",
        "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
        "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
        "\n",
        "            # Compute gradients of output Z with respect to weight, bias, input\n",
        "            dZ_dw = self.flattened_input\n",
        "            dZ_db = 1\n",
        "            dZ_dX = self.weight\n",
        "\n",
        "            # Gradient of loss with respect ot output\n",
        "            dE_dZ = gradient * dY_dZ\n",
        "\n",
        "            # Gradient of loss with respect to weight, bias, input\n",
        "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
        "            dE_db = dE_dZ * dZ_db\n",
        "            dE_dX = dZ_dX @ dE_dZ\n",
        "\n",
        "            # Update parameters\n",
        "            self.weight -= alpha*dE_dw\n",
        "            self.bias -= alpha*dE_db\n",
        "\n",
        "            return dE_dX.reshape(self.original_shape)\n"
      ],
      "metadata": {
        "id": "PQhXoXkHVdq9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Training Functions"
      ],
      "metadata": {
        "id": "b_l0VGZSZjHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_forward(image, label, layers):\n",
        "    output = image/255.\n",
        "    for layer in layers:\n",
        "        output = layer.forward_prop(output)\n",
        "    # Compute loss (cross-entropy) and accuracy\n",
        "    loss = -np.log(output[label])\n",
        "    accuracy = 1 if np.argmax(output) == label else 0\n",
        "    return output, loss, accuracy\n",
        "\n",
        "def CNN_backprop(gradient, layers, alpha=0.05):\n",
        "    grad_back = gradient\n",
        "    for layer in layers[::-1]:\n",
        "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
        "            grad_back = layer.back_prop(grad_back, alpha)\n",
        "        elif type(layer) == MaxPoolingLayer:\n",
        "            grad_back = layer.back_prop(grad_back)\n",
        "    return grad_back\n",
        "\n",
        "\n",
        "def CNN_training(image, label, layers, alpha=0.05):\n",
        "    # Forward step\n",
        "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
        "\n",
        "    # Initial gradient\n",
        "    gradient = np.zeros(10)\n",
        "    gradient[label] = -1/output[label]\n",
        "\n",
        "    # Backprop step\n",
        "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
        "\n",
        "    return loss, accuracy\n"
      ],
      "metadata": {
        "id": "XDBnmhvDVfcW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with 10000 images sample from MNIST"
      ],
      "metadata": {
        "id": "eTW6tI7IZtxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Load training data\n",
        "  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  X_train = X_train[:10000]\n",
        "  y_train = y_train[:10000]\n",
        "\n",
        "  # Define the network\n",
        "  layers = [\n",
        "    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
        "    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)\n",
        "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
        "    ]\n",
        "\n",
        "  for epoch in range(1):\n",
        "    print('Epoch {} ->'.format(epoch+1))\n",
        "    # Shuffle training data\n",
        "    permutation = np.random.permutation(len(X_train))\n",
        "    X_train = X_train[permutation]\n",
        "    y_train = y_train[permutation]\n",
        "    # Training the CNN\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
        "      if i % 100 == 0: # Every 100 examples\n",
        "        print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "      loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
        "      loss += loss_1\n",
        "      accuracy += accuracy_1\n",
        "\n"
      ],
      "metadata": {
        "id": "C36BCAy2VjLt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the processing time of ANN's Sequential Version"
      ],
      "metadata": {
        "id": "865AJqYzZ0CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhN17fgmV0n3",
        "outputId": "71be9421-737a-449b-f007-67414fba5b03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ->\n",
            "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n",
            "Step 101. For the last 100 steps: average loss 1.8038023710107765, accuracy 39\n",
            "Step 201. For the last 100 steps: average loss 1.0313300497109616, accuracy 62\n",
            "Step 301. For the last 100 steps: average loss 0.7009510400483169, accuracy 77\n",
            "Step 401. For the last 100 steps: average loss 0.6889733515027316, accuracy 75\n",
            "Step 501. For the last 100 steps: average loss 0.5999658988659795, accuracy 81\n",
            "Step 601. For the last 100 steps: average loss 0.6394897102629741, accuracy 82\n",
            "Step 701. For the last 100 steps: average loss 0.5771108812912289, accuracy 82\n",
            "Step 801. For the last 100 steps: average loss 0.5821409779792328, accuracy 81\n",
            "Step 901. For the last 100 steps: average loss 0.4222261432857698, accuracy 83\n",
            "Step 1001. For the last 100 steps: average loss 0.4775696051759018, accuracy 86\n",
            "Step 1101. For the last 100 steps: average loss 0.4309584158757647, accuracy 85\n",
            "Step 1201. For the last 100 steps: average loss 0.594187029920888, accuracy 83\n",
            "Step 1301. For the last 100 steps: average loss 0.3937972749759615, accuracy 88\n",
            "Step 1401. For the last 100 steps: average loss 0.5426952652007967, accuracy 84\n",
            "Step 1501. For the last 100 steps: average loss 0.5530816775578292, accuracy 81\n",
            "Step 1601. For the last 100 steps: average loss 0.534636417973514, accuracy 85\n",
            "Step 1701. For the last 100 steps: average loss 0.45863630647726544, accuracy 87\n",
            "Step 1801. For the last 100 steps: average loss 0.558952553021205, accuracy 80\n",
            "Step 1901. For the last 100 steps: average loss 0.5789761761469383, accuracy 84\n",
            "Step 2001. For the last 100 steps: average loss 0.47304466259571254, accuracy 86\n",
            "Step 2101. For the last 100 steps: average loss 0.647842295157323, accuracy 82\n",
            "Step 2201. For the last 100 steps: average loss 0.5729746236800096, accuracy 86\n",
            "Step 2301. For the last 100 steps: average loss 0.4120920590316222, accuracy 87\n",
            "Step 2401. For the last 100 steps: average loss 0.37378806572310547, accuracy 90\n",
            "Step 2501. For the last 100 steps: average loss 0.5570177732049213, accuracy 81\n",
            "Step 2601. For the last 100 steps: average loss 0.44843280386641177, accuracy 88\n",
            "Step 2701. For the last 100 steps: average loss 0.5946687886867623, accuracy 84\n",
            "Step 2801. For the last 100 steps: average loss 0.5963788426754515, accuracy 77\n",
            "Step 2901. For the last 100 steps: average loss 0.19351431361264282, accuracy 93\n",
            "Step 3001. For the last 100 steps: average loss 0.4321403249196269, accuracy 85\n",
            "Step 3101. For the last 100 steps: average loss 0.31574217570705626, accuracy 90\n",
            "Step 3201. For the last 100 steps: average loss 0.35523029045419546, accuracy 91\n",
            "Step 3301. For the last 100 steps: average loss 0.5695896181806672, accuracy 84\n",
            "Step 3401. For the last 100 steps: average loss 0.41131934426678174, accuracy 90\n",
            "Step 3501. For the last 100 steps: average loss 0.5538225090355262, accuracy 82\n",
            "Step 3601. For the last 100 steps: average loss 0.5556553549626451, accuracy 86\n",
            "Step 3701. For the last 100 steps: average loss 0.30808604409781337, accuracy 91\n",
            "Step 3801. For the last 100 steps: average loss 0.3698765395361841, accuracy 88\n",
            "Step 3901. For the last 100 steps: average loss 0.40389034627198517, accuracy 87\n",
            "Step 4001. For the last 100 steps: average loss 0.5856747008906769, accuracy 87\n",
            "Step 4101. For the last 100 steps: average loss 0.6109676464085756, accuracy 81\n",
            "Step 4201. For the last 100 steps: average loss 0.4607259946119088, accuracy 85\n",
            "Step 4301. For the last 100 steps: average loss 0.41364371317328774, accuracy 87\n",
            "Step 4401. For the last 100 steps: average loss 0.2708608959089252, accuracy 95\n",
            "Step 4501. For the last 100 steps: average loss 0.2818900968282324, accuracy 91\n",
            "Step 4601. For the last 100 steps: average loss 0.299647021013868, accuracy 90\n",
            "Step 4701. For the last 100 steps: average loss 0.32305299489803363, accuracy 91\n",
            "Step 4801. For the last 100 steps: average loss 0.31834780920138306, accuracy 92\n",
            "Step 4901. For the last 100 steps: average loss 0.6061679613289274, accuracy 81\n",
            "Step 5001. For the last 100 steps: average loss 0.23577002175343345, accuracy 92\n",
            "Step 5101. For the last 100 steps: average loss 0.3274666154463917, accuracy 89\n",
            "Step 5201. For the last 100 steps: average loss 0.18301000535883993, accuracy 94\n",
            "Step 5301. For the last 100 steps: average loss 0.36404364589051136, accuracy 89\n",
            "Step 5401. For the last 100 steps: average loss 0.28437412428243414, accuracy 93\n",
            "Step 5501. For the last 100 steps: average loss 0.380699256025568, accuracy 88\n",
            "Step 5601. For the last 100 steps: average loss 0.5992466253597605, accuracy 85\n",
            "Step 5701. For the last 100 steps: average loss 0.2770429934870525, accuracy 88\n",
            "Step 5801. For the last 100 steps: average loss 0.414929736220315, accuracy 88\n",
            "Step 5901. For the last 100 steps: average loss 0.36267374108568673, accuracy 91\n",
            "Step 6001. For the last 100 steps: average loss 0.4643180582583106, accuracy 86\n",
            "Step 6101. For the last 100 steps: average loss 0.22023154475234535, accuracy 94\n",
            "Step 6201. For the last 100 steps: average loss 0.3849447734632999, accuracy 87\n",
            "Step 6301. For the last 100 steps: average loss 0.2966203055387921, accuracy 93\n",
            "Step 6401. For the last 100 steps: average loss 0.21797805634910306, accuracy 95\n",
            "Step 6501. For the last 100 steps: average loss 0.5624102904063414, accuracy 84\n",
            "Step 6601. For the last 100 steps: average loss 0.44646537875256465, accuracy 90\n",
            "Step 6701. For the last 100 steps: average loss 0.2843440734207152, accuracy 94\n",
            "Step 6801. For the last 100 steps: average loss 0.36385614043163145, accuracy 90\n",
            "Step 6901. For the last 100 steps: average loss 0.33732170470948525, accuracy 90\n",
            "Step 7001. For the last 100 steps: average loss 0.2677189952509211, accuracy 92\n",
            "Step 7101. For the last 100 steps: average loss 0.5298791813128371, accuracy 86\n",
            "Step 7201. For the last 100 steps: average loss 0.3731279451362673, accuracy 89\n",
            "Step 7301. For the last 100 steps: average loss 0.46101491009811446, accuracy 89\n",
            "Step 7401. For the last 100 steps: average loss 0.5015746766981987, accuracy 88\n",
            "Step 7501. For the last 100 steps: average loss 0.5489492246369436, accuracy 83\n",
            "Step 7601. For the last 100 steps: average loss 0.3073480822614508, accuracy 90\n",
            "Step 7701. For the last 100 steps: average loss 0.4529951105732773, accuracy 88\n",
            "Step 7801. For the last 100 steps: average loss 0.18778544345362203, accuracy 96\n",
            "Step 7901. For the last 100 steps: average loss 0.4729944068636064, accuracy 90\n",
            "Step 8001. For the last 100 steps: average loss 0.33927847841866743, accuracy 91\n",
            "Step 8101. For the last 100 steps: average loss 0.40784260225423935, accuracy 88\n",
            "Step 8201. For the last 100 steps: average loss 0.3571723461768147, accuracy 89\n",
            "Step 8301. For the last 100 steps: average loss 0.5652773300444821, accuracy 83\n",
            "Step 8401. For the last 100 steps: average loss 0.31727213810875254, accuracy 92\n",
            "Step 8501. For the last 100 steps: average loss 0.437041309373821, accuracy 89\n",
            "Step 8601. For the last 100 steps: average loss 0.5170853641101014, accuracy 87\n",
            "Step 8701. For the last 100 steps: average loss 0.47419252598852857, accuracy 86\n",
            "Step 8801. For the last 100 steps: average loss 0.4201936235317494, accuracy 87\n",
            "Step 8901. For the last 100 steps: average loss 0.23011271692168286, accuracy 95\n",
            "Step 9001. For the last 100 steps: average loss 0.3192422999534482, accuracy 94\n",
            "Step 9101. For the last 100 steps: average loss 0.42000411434600404, accuracy 90\n",
            "Step 9201. For the last 100 steps: average loss 0.37113101634486734, accuracy 89\n",
            "Step 9301. For the last 100 steps: average loss 0.4063463795291023, accuracy 87\n",
            "Step 9401. For the last 100 steps: average loss 0.2767561076825206, accuracy 93\n",
            "Step 9501. For the last 100 steps: average loss 0.3127431005162966, accuracy 90\n",
            "Step 9601. For the last 100 steps: average loss 0.25605012217842416, accuracy 92\n",
            "Step 9701. For the last 100 steps: average loss 0.5119591857685697, accuracy 84\n",
            "Step 9801. For the last 100 steps: average loss 0.4704093313567531, accuracy 86\n",
            "Step 9901. For the last 100 steps: average loss 0.3874862768397129, accuracy 89\n",
            "CPU times: user 20min 23s, sys: 13min 55s, total: 34min 19s\n",
            "Wall time: 19min 43s\n"
          ]
        }
      ]
    }
  ]
}